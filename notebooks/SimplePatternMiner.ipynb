{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed9889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log initialized. Log file: /tmp/das.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1702797, 27871440)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from das.distributed_atom_space import DistributedAtomSpace, QueryOutputFormat\n",
    "from das.database.db_interface import UNORDERED_LINK_TYPES\n",
    "from das.pattern_matcher.pattern_matcher import PatternMatchingAnswer, OrderedAssignment, UnorderedAssignment, CompositeAssignment, Node, Link, Variable, Not, And, Or, TypedVariable, LinkTemplate\n",
    "from das.database.db_interface import WILDCARD\n",
    "from das.expression_hasher import ExpressionHasher\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "warnings.filterwarnings('ignore')\n",
    "TARGET_NODES = None\n",
    "das = DistributedAtomSpace()\n",
    "db = das.db\n",
    "das.count_atoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a828f3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80ef77c79ab33f7a7e5d3070a09ded02\n"
     ]
    }
   ],
   "source": [
    "def get_gene_node(name):\n",
    "    verbatim_node = das.get_node(\"Verbatim\", name)\n",
    "    schema_node = das.get_node(\"Schema\", \"Schema:sql_gene_name\")\n",
    "    print(f\"verbatim_node = {verbatim_node}\")\n",
    "    print(f\"schema_node = {schema_node}\")\n",
    "    v1 = Variable(\"v1\")\n",
    "    links = das.get_links(\"Execution\", None, [schema_node, WILDCARD, verbatim_node])\n",
    "    print(f\"links = {links}\")\n",
    "    link = das.get_atom(links[0], output_format=QueryOutputFormat.ATOM_INFO)\n",
    "    print(f\"link = {link}\")\n",
    "    gene_node_handle = link[\"targets\"][1]\n",
    "    print(f\"gene_node_handle = {gene_node_handle}\")\n",
    "    gene_node = das.get_atom(gene_node_handle, output_format=QueryOutputFormat.ATOM_INFO)\n",
    "    print(f\"gene_node = {gene_node}\")\n",
    "    return Node(\"gene\", gene_node[\"name\"])\n",
    "\n",
    "print(das.get_node(\"gene\", \"3106709\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a871700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_LIST = [\n",
    "    \"mus101\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13079c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatim_node = 9a65a498651b799372edaf3ad3f639c0\n",
      "schema_node = 7494788453289a15a95f81a916c9cc21\n",
      "links = ['49c763399ab9dcae90a10377fb73e65f']\n",
      "link = {'handle': '49c763399ab9dcae90a10377fb73e65f', 'type': 'Execution', 'template': ['Execution', 'Schema', 'gene', 'Verbatim'], 'targets': ['7494788453289a15a95f81a916c9cc21', '80ef77c79ab33f7a7e5d3070a09ded02', '9a65a498651b799372edaf3ad3f639c0']}\n",
      "gene_node_handle = 80ef77c79ab33f7a7e5d3070a09ded02\n",
      "gene_node = {}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     TARGET_SUBSTRING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     TARGET_NODES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m         get_gene_node(gene) \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m GENE_LIST\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m NGRAM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     12\u001b[0m SUPPORT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     TARGET_SUBSTRING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     TARGET_NODES \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mget_gene_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgene\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m GENE_LIST\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m NGRAM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     12\u001b[0m SUPPORT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mget_gene_node\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     13\u001b[0m gene_node \u001b[38;5;241m=\u001b[39m das\u001b[38;5;241m.\u001b[39mget_atom(gene_node_handle, output_format\u001b[38;5;241m=\u001b[39mQueryOutputFormat\u001b[38;5;241m.\u001b[39mATOM_INFO)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_node = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgene_node\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mgene_node\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "USE_SUBSTRING = False\n",
    "\n",
    "if USE_SUBSTRING:\n",
    "    TARGET_TYPE = \"Concept\"\n",
    "    TARGET_SUBSTRING = \"gl\"\n",
    "else:\n",
    "    TARGET_NODES = [\n",
    "        get_gene_node(gene) for gene in GENE_LIST\n",
    "    ]\n",
    "\n",
    "NGRAM = 3\n",
    "SUPPORT = 0\n",
    "HALO_LENGTH = 2\n",
    "DEPTH_WEIGTH = [1, 1]\n",
    "ISURPRISINGNESS_REPORT_THRESHOLD = 0\n",
    "EPOCHS = 1000\n",
    "NORMALIZED_ISURPRISINGNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a70779e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEPTH_WEIGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mDEPTH_WEIGTH\u001b[49m) \u001b[38;5;241m==\u001b[39m HALO_LENGTH\n\u001b[1;32m      2\u001b[0m halo_levels \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(HALO_LENGTH)]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TARGET_NODES \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEPTH_WEIGTH' is not defined"
     ]
    }
   ],
   "source": [
    "assert len(DEPTH_WEIGTH) == HALO_LENGTH\n",
    "halo_levels = [i for i in range(HALO_LENGTH)]\n",
    "if TARGET_NODES is None:\n",
    "    atomspace_nodes = db.get_matched_node_name(TARGET_TYPE, TARGET_SUBSTRING)\n",
    "    print(atomspace_nodes)\n",
    "    TARGET_NODES = [Node(TARGET_TYPE, db.get_node_name(h)) for h in atomspace_nodes]\n",
    "print(f\"TARGET_NODES = {TARGET_NODES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ordered_assignment(assignment):\n",
    "    if assignment is not None:\n",
    "        for key, value in assignment.mapping.items():\n",
    "            print(f\"{key}: {db.get_node_name(value)}\")\n",
    "\n",
    "def print_unordered_assignment(assignment):\n",
    "    if assignment is not None:\n",
    "        symbols = []\n",
    "        for key in assignment.symbols:\n",
    "            for i in range(assignment.symbols[key]):\n",
    "                symbols.append(key)\n",
    "        values = []\n",
    "        for key in assignment.values:\n",
    "            for i in range(assignment.values[key]):\n",
    "                values.append(key)\n",
    "        mapping_keys = []\n",
    "        mapping_values = []\n",
    "        for symbol, value in zip(symbols, values):\n",
    "            mapping_keys.append(symbol)\n",
    "            mapping_values.append(db.get_node_name(value))\n",
    "        print(f\"{mapping_keys} = {mapping_values}\")\n",
    "        \n",
    "def build_pattern_from_template(template):\n",
    "    targets = []\n",
    "    count_variables = 1\n",
    "    for target in template[1:]:\n",
    "        if target == WILDCARD:\n",
    "            targets.append(Variable(f\"V{count_variables}\"))\n",
    "            count_variables += 1\n",
    "        else:\n",
    "            #node_document = das.get_atom(target, output_format=QueryOutputFormat.ATOM_INFO)\n",
    "            try:\n",
    "                node_type = das.get_node_type(target)\n",
    "                node_name = das.get_node_name(target)\n",
    "                targets.append(Node(node_type, node_name))\n",
    "            except:\n",
    "                return None\n",
    "    return Link(template[0], ordered=(template[0] not in UNORDERED_LINK_TYPES), targets=targets)\n",
    "\n",
    "def _random_selection(v):\n",
    "    return v[np.random.randint(len(v))]\n",
    "\n",
    "def random_selection(v, n=1):\n",
    "    if n == 1:\n",
    "        return _random_selection(v)\n",
    "    assert n <= (len(v) / 2)\n",
    "    a = v.copy()\n",
    "    selected = []\n",
    "    for i in range(n):\n",
    "        s = _random_selection(a)\n",
    "        a.remove(s)\n",
    "        selected.append(s)\n",
    "    return selected\n",
    "\n",
    "def build_roulette(w):\n",
    "    answer = []\n",
    "    s = sum(w)\n",
    "    acc = 0\n",
    "    for v in w:\n",
    "        acc += v / s\n",
    "        answer.append(acc)\n",
    "    answer[-1] = 1\n",
    "    return answer\n",
    "\n",
    "def roulette_selection(v, w):\n",
    "    assert len(v) == len(w)\n",
    "    random = np.random.random()\n",
    "    for i in range(len(v)):\n",
    "        if random <= w[i]:\n",
    "            return v[i]\n",
    "    \n",
    "def compute_count(logical_expression):\n",
    "    query_answer = PatternMatchingAnswer()\n",
    "    matched = logical_expression.matched(db, query_answer)\n",
    "    return len(query_answer.assignments) if matched else 0\n",
    "        \n",
    "def prob(count):\n",
    "    return count / universe_size\n",
    "\n",
    "def compute_isurprisingness(count, terms, term_handles, counts, normalized = False):\n",
    "    n = len(term_handles)\n",
    "    if n == 2:\n",
    "        subset_probs = [prob(counts[0]) * prob(counts[1])]\n",
    "    elif n == 3:\n",
    "        subset_probs = [\n",
    "            prob(counts[0]) * prob(counts[1]) * prob(counts[2]),\n",
    "            prob(compute_count(And([terms[0], terms[1]]))) * prob(counts[2]), \n",
    "            prob(compute_count(And([terms[0], terms[2]]))) * prob(counts[1]),\n",
    "            prob(compute_count(And([terms[1], terms[2]]))) * prob(counts[0])\n",
    "        ]\n",
    "    elif n == 4:\n",
    "        subset_probs = [\n",
    "            prob(counts[0]) * prob(counts[1]) * prob(counts[2]) * prob(counts[3]),\n",
    "            prob(compute_count(And([terms[0], terms[1]]))) * prob(compute_count(And([terms[2], terms[3]]))),\n",
    "            prob(compute_count(And([terms[0], terms[2]]))) * prob(compute_count(And([terms[1], terms[3]]))),\n",
    "            prob(compute_count(And([terms[0], terms[3]]))) * prob(compute_count(And([terms[1], terms[2]]))),\n",
    "            prob(compute_count(And([terms[0], terms[1], terms[2]]))) * prob(counts[3]),\n",
    "            prob(compute_count(And([terms[0], terms[1], terms[3]]))) * prob(counts[2]),\n",
    "            prob(compute_count(And([terms[0], terms[2], terms[3]]))) * prob(counts[1]),\n",
    "            prob(compute_count(And([terms[1], terms[2], terms[3]]))) * prob(counts[0])\n",
    "        ]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    p = prob(count)\n",
    "    isurprisingness = max([p - max(subset_probs), min(subset_probs) - p])\n",
    "    if normalized:\n",
    "        return isurprisingness / p\n",
    "    else:\n",
    "        return isurprisingness\n",
    "    \n",
    "def build_patterns(links):\n",
    "    pattern = {}\n",
    "    pattern_count = {}\n",
    "    link_count = 0\n",
    "    for link in links:\n",
    "        link_count += 1\n",
    "        if link_count % 100000 == 0 or link_count == 1 or link_count == len(links):\n",
    "            print(f\"link {link_count}/{len(links)}\")\n",
    "        #link_document = das.get_atom(link, output_format=QueryOutputFormat.ATOM_INFO)\n",
    "        #targets = link_document['targets']\n",
    "        #link_type = link_document['type']\n",
    "        targets = das.get_link_targets(link)\n",
    "        link_type = das.get_link_type(link)\n",
    "        arity = len(targets)\n",
    "        if arity == 2:\n",
    "            templates = [\n",
    "                [link_type, WILDCARD, targets[1]],\n",
    "                [link_type, targets[0], WILDCARD],\n",
    "                #[link_type, WILDCARD, WILDCARD],\n",
    "            ]\n",
    "        elif arity == 3:\n",
    "            templates = [\n",
    "                [link_type, WILDCARD, targets[1], targets[2]],\n",
    "                [link_type, targets[0], WILDCARD, targets[2]],\n",
    "                [link_type, targets[0], targets[1], WILDCARD],\n",
    "                [link_type, WILDCARD, WILDCARD, targets[2]],\n",
    "                [link_type, WILDCARD, targets[1], WILDCARD],\n",
    "                [link_type, targets[0], WILDCARD, WILDCARD],\n",
    "                #[link_type, WILDCARD, WILDCARD, WILDCARD],\n",
    "            ]\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        for template in templates:\n",
    "            p = build_pattern_from_template(template)\n",
    "            if p is not None:\n",
    "                template_handle = ExpressionHasher.composite_hash(template)\n",
    "                pattern[template_handle] = p\n",
    "                pattern_count[template_handle] = len(das.get_links(template[0], None, template[1:]))\n",
    "    return tuple([pattern, pattern_count])\n",
    "        \n",
    "def build_composite_pattern(terms):\n",
    "    assert len(terms) > 1\n",
    "    for i in range(len(terms)):\n",
    "        if i == 0:\n",
    "            first_term = terms[i]\n",
    "        else:\n",
    "            second_term = terms[i]\n",
    "            composite_pattern = And([first_term, second_term])\n",
    "            first_term = composite_pattern\n",
    "    return composite_pattern\n",
    "    \n",
    "def print_query(pattern):\n",
    "    print(pattern)\n",
    "    query_answer = PatternMatchingAnswer()\n",
    "    pattern.matched(db, query_answer)\n",
    "    for assignment in query_answer.assignments:\n",
    "        if type(assignment) is OrderedAssignment:\n",
    "            print_ordered_assignment(assignment)\n",
    "        elif type(assignment) is UnorderedAssignment:\n",
    "            print_unordered_assignment(assignment)\n",
    "        elif type(assignment) is CompositeAssignment:\n",
    "            print_ordered_assignment(assignment.ordered_mapping)\n",
    "            for unordered_assignment in assignment.unordered_mappings:\n",
    "                print_unordered_assignment(unordered_assignment)\n",
    "        print(\"\")\n",
    "        \n",
    "halo_level_roulette = build_roulette(DEPTH_WEIGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_handle_list = set([ExpressionHasher.terminal_hash(n.atom_type, n.name) for n in TARGET_NODES])\n",
    "print(f\"node_handle_list = {node_handle_list}\")\n",
    "links = [set() for i in range(HALO_LENGTH)]\n",
    "for level in range(HALO_LENGTH):\n",
    "    new_level_node_handles = set()\n",
    "    node_handle_count = 0\n",
    "    for node_handle in node_handle_list:\n",
    "        node_handle_count += 1\n",
    "        #print(f\"===========================================\")\n",
    "        print(f\"Halo level {level+1}/{HALO_LENGTH} node_handle {node_handle_count}/{len(node_handle_list)}\")\n",
    "        template_list = [\n",
    "            [node_handle, WILDCARD], \n",
    "            [WILDCARD, node_handle], \n",
    "            [node_handle, WILDCARD, WILDCARD], \n",
    "            [WILDCARD, node_handle, WILDCARD], \n",
    "            [WILDCARD, WILDCARD, node_handle]\n",
    "        ]\n",
    "        for template in template_list:\n",
    "            #print(f\"template = {template}\")\n",
    "            link_list = set(das.get_links(None, None, template))\n",
    "            #print(f\"len(link_list) = {len(link_list)}\")\n",
    "            for link in link_list:\n",
    "                #link_document = das.get_atom(link, output_format=QueryOutputFormat.ATOM_INFO)\n",
    "                for h in das.get_link_targets(link):\n",
    "                    new_level_node_handles.add(h)\n",
    "            links[level].update(link_list)\n",
    "    node_handle_list.update(new_level_node_handles)\n",
    "for level in range(HALO_LENGTH):\n",
    "    if level == 0:\n",
    "        all_links = set([link for link in links[level]])\n",
    "    else:\n",
    "        links[level] = links[level].difference(all_links)\n",
    "        all_links.update(links[level])\n",
    "universe_size = len(all_links)\n",
    "print(f\"===========================================\")\n",
    "print(f\"Done - universe_size = {universe_size}\")\n",
    "print(f\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86744255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(node_handle_list)\n",
    "#print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for level in range(HALO_LENGTH):\n",
    "    total += len(links[level])\n",
    "    print(len(links[level]))\n",
    "print(\"----------\")\n",
    "print(total)\n",
    "#links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [None for i in range(HALO_LENGTH)]\n",
    "pattern_count = [None for i in range(HALO_LENGTH)]\n",
    "pattern_handles = [None for i in range(HALO_LENGTH)]\n",
    "all_patterns = {}\n",
    "all_patterns_count = {}\n",
    "for level in range(HALO_LENGTH):\n",
    "    print(f\"###########################################\")\n",
    "    print(f\"Building patterns for level {level}\")\n",
    "    pattern[level], pattern_count[level] = build_patterns(links[level])\n",
    "    pattern_handles[level] = [key for key in pattern[level].keys()]\n",
    "    for key, value in pattern[level].items():\n",
    "        all_patterns[key] = value\n",
    "    for key, value in pattern_count[level].items():\n",
    "        all_patterns_count[key] = value\n",
    "print(f\"===========================================\")\n",
    "print(f\"Done - len(all_patterns) = {len(all_patterns)}\")\n",
    "print(f\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for level in range(HALO_LENGTH):\n",
    "    total += len(pattern_handles[level])\n",
    "    print(len(pattern_handles[level]))\n",
    "print(\"----------\")\n",
    "print(total)\n",
    "#pattern_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c1d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "higher_isurprisingness = 0\n",
    "best_pattern = None\n",
    "for i in range(EPOCHS):\n",
    "    if i % 1000 == 0 or i == EPOCHS - 1:\n",
    "        print(f\"Epoch {i + 1}/{EPOCHS}\")\n",
    "    selected_handle = random_selection(pattern_handles[0])\n",
    "    term_handles = [tuple([selected_handle, 0])]\n",
    "    terms = [pattern[0][selected_handle]]\n",
    "    counts = [pattern_count[0][selected_handle]]\n",
    "    for i in range(NGRAM - 1):\n",
    "        while True:\n",
    "            selected_level = roulette_selection(halo_levels, halo_level_roulette)\n",
    "            selected_handle = random_selection(pattern_handles[selected_level])\n",
    "            if tuple([selected_handle, selected_level]) not in term_handles:\n",
    "                break\n",
    "        term_handles.append(tuple([selected_handle, selected_level]))\n",
    "        terms.append(pattern[selected_level][selected_handle])\n",
    "        counts.append(pattern_count[selected_level][selected_handle])\n",
    "    composite_pattern = build_composite_pattern(terms)\n",
    "    count = compute_count(composite_pattern)\n",
    "    if count > 0:\n",
    "        print(f\"Count: {count}\")\n",
    "    if count >= SUPPORT:\n",
    "        isurprisingness = compute_isurprisingness(count, terms, term_handles, counts, normalized=NORMALIZED_ISURPRISINGNESS) \n",
    "        if isurprisingness > higher_isurprisingness:\n",
    "            print(f\"{count} {isurprisingness}: {terms} {term_handles} {counts}\")\n",
    "            higher_isurprisingness = isurprisingness\n",
    "            best_pattern = composite_pattern\n",
    "print_query(best_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_isurprisingness = 0\n",
    "best_pattern = None\n",
    "all_patterns_handles = all_patterns.keys()\n",
    "\n",
    "count_bh = 0\n",
    "for basic_handle in pattern_handles[0]:\n",
    "    count_bh += 1\n",
    "    print(f\"Cycle {count_bh}/{len(pattern_handles[0])}\")\n",
    "    for combination_handles in combinations(all_patterns, NGRAM - 1):\n",
    "        if basic_handle in combination_handles:\n",
    "            continue\n",
    "        term_handles = [basic_handle, *combination_handles]\n",
    "        terms = [all_patterns[handle] for handle in term_handles]\n",
    "        counts = [all_patterns_count[handle] for handle in term_handles]\n",
    "        composite_pattern = build_composite_pattern(terms)\n",
    "        count = compute_count(composite_pattern)\n",
    "        if count >= SUPPORT:\n",
    "            isurprisingness = compute_isurprisingness(count, terms, term_handles, counts, normalized=NORMALIZED_ISURPRISINGNESS) \n",
    "            if isurprisingness > higher_isurprisingness:\n",
    "                print(f\"{count} {isurprisingness}: {terms} {counts}\")\n",
    "                higher_isurprisingness = isurprisingness\n",
    "                best_pattern = composite_pattern    \n",
    "print_query(best_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ff166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
